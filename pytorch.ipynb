{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOi2AwryFXojn8wExpgSjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PranshuGhori/ClassificationPython/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zzDarIko1Nta"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "metadata": {
        "id": "NjpviL1X11aX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "9lLrcvZx2cQO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert inputs and targets to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "eovi3w-92iBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d54f48-0b45-4b7b-ca6c-b884273e06d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(2,3,requires_grad=True)\n",
        "b = torch.randn(2,requires_grad=True)"
      ],
      "metadata": {
        "id": "qsqORWyk3qfm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X):\n",
        "  return X @ w.t() + b"
      ],
      "metadata": {
        "id": "cpZ4t7HX4ELB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)"
      ],
      "metadata": {
        "id": "UtJ8JreL4NHC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "id": "UKYf-dWS4M5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2905c28c-5d58-4f22-d103-ad5e9ef05121"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(t1,t2):\n",
        "  diff = t1-t2\n",
        "  return torch.sum(diff*diff)/diff.numel()\n"
      ],
      "metadata": {
        "id": "M8U0_ywt4akw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = mse(preds,targets)\n",
        "loss.backward"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CbOcQ3xD4okB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "94e214f7-b4d7-4a26-f08c-cf98f8aa7514"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Tensor.backward of tensor(7789.3252, grad_fn=<DivBackward0>)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch._tensor.Tensor.backward</b><br/>def backward(gradient=None, retain_graph=None, create_graph=False, inputs=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/torch/_tensor.py</a>Computes the gradient of current tensor wrt graph leaves.\n",
              "\n",
              "The graph is differentiated using the chain rule. If the tensor is\n",
              "non-scalar (i.e. its data has more than one element) and requires\n",
              "gradient, the function additionally requires specifying a ``gradient``.\n",
              "It should be a tensor of matching type and shape, that represents\n",
              "the gradient of the differentiated function w.r.t. ``self``.\n",
              "\n",
              "This function accumulates gradients in the leaves - you might need to zero\n",
              "``.grad`` attributes or set them to ``None`` before calling it.\n",
              "See :ref:`Default gradient layouts&lt;default-grad-layouts&gt;`\n",
              "for details on the memory layout of accumulated gradients.\n",
              "\n",
              ".. note::\n",
              "\n",
              "    If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
              "    in a user-specified CUDA stream context, see\n",
              "    :ref:`Stream semantics of backward passes&lt;bwd-cuda-stream-semantics&gt;`.\n",
              "\n",
              ".. note::\n",
              "\n",
              "    When ``inputs`` are provided and a given input is not a leaf,\n",
              "    the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n",
              "    It is an implementation detail on which the user should not rely.\n",
              "    See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n",
              "\n",
              "Args:\n",
              "    gradient (Tensor, optional): The gradient of the function\n",
              "        being differentiated w.r.t. ``self``.\n",
              "        This argument can be omitted if ``self`` is a scalar. Defaults to ``None``.\n",
              "    retain_graph (bool, optional): If ``False``, the graph used to compute the grads will be freed;\n",
              "        If ``True``, it will be retained. The default is ``None``, in which case the value is inferred from ``create_graph``\n",
              "        (i.e., the graph is retained only when higher-order derivative tracking is requested). Note that in nearly all cases\n",
              "        setting this option to True is not needed and often can be worked around in a much more efficient way.\n",
              "    create_graph (bool, optional): If ``True``, graph of the derivative will\n",
              "        be constructed, allowing to compute higher order derivative\n",
              "        products. Defaults to ``False``.\n",
              "    inputs (Sequence[Tensor], optional): Inputs w.r.t. which the gradient will be\n",
              "        accumulated into ``.grad``. All other tensors will be ignored. If not\n",
              "        provided, the gradient is accumulated into all the leaf Tensors that were\n",
              "        used to compute the :attr:`tensors`. Defaults to ``None``.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 575);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  w -= w.grad * 1e-5\n",
        "  b -= b.grad * 1e-5"
      ],
      "metadata": {
        "id": "9-n5gYPy4t90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "7b1557fe-a69d-4a34-ce10-42ff931b2fa1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for *: 'NoneType' and 'float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-399/1819158025.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "8OFYXKDA5C5B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "55c0ee41-41e6-469a-dc9c-50342dc0fe08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'zero_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-399/4198022957.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'zero_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preads = model(inputs)\n",
        "preads"
      ],
      "metadata": {
        "id": "daImKLhN5I94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ab3afe-ffe5-48db-f80b-d3b20594ce5f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-23.3319,  38.0617],\n",
              "        [-22.0930,  63.2583],\n",
              "        [-72.6053, 120.1583],\n",
              "        [ -8.3549, -33.0814],\n",
              "        [-22.0690, 105.7906]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = mse(preds, targets)\n",
        "loss"
      ],
      "metadata": {
        "id": "VBwk8WYp5TDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "metadata": {
        "id": "AWpW3qKyr5MW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MNIST(root='data/', download=True)"
      ],
      "metadata": {
        "id": "di5lUw0wtOc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430dc94e-014f-4380-bbbc-914f17b5a6a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.24MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 165kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.55MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.94MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCupBCSotZKY",
        "outputId": "ffe2c8c7-5fc9-46bc-bd97-1b52a3cc9358"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = MNIST(root='data/', train=False)\n",
        "len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja2yyjo7tbzZ",
        "outputId": "cdc951d5-fa92-454a-9921-b8065319e74b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8JCIaXctoR6",
        "outputId": "c379e4c3-dcc2-4292-f324-01a8ccfeac19"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28>, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "OC8zh4mitxLp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = dataset[230]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print('Label:', label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "xnLCa4DPt3Qg",
        "outputId": "3b55f171-cc27-4755-f6cf-bf253ba2fae2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "dataset = MNIST(root='data/',\n",
        "                train=True,\n",
        "                transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "baCXDHCS9FK6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor, label = dataset[0]\n"
      ],
      "metadata": {
        "id": "-ukA7h1t9MNt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img_tensor.shape, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcCPTlmK9Sok",
        "outputId": "9d61e834-09d2-4ef5-d8c6-7878a0e57eff"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(img_tensor[0,10:15,10:15])\n",
        "print(torch.max(img_tensor), torch.min(img_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfuescPI_sOk",
        "outputId": "675a6e1c-1fdd-44b4-de47-4025e8378361"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
            "        [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
            "        [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
            "        [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
            "        [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]])\n",
            "tensor(1.) tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_tensor[0,10:15,10:15], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Er_eIyXN_9wV",
        "outputId": "61ea8ce3-27c8-47d4-b999-7c26ea531e83"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7c46dd3fc7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Validation"
      ],
      "metadata": {
        "id": "Z554d-4AE1gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE6p0kwuE5AP",
        "outputId": "25ddd45e-9ef2-47a3-c727-bd605bfacdaf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_ds, batch_size = 128, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "metadata": {
        "id": "aPo4VOB8FsBs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "input_size = 28*28\n",
        "num_classes = 10\n",
        "\n",
        "model = nn.Linear(input_size, num_classes)"
      ],
      "metadata": {
        "id": "hBdXxP-KHqFk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9b6MqvpID5v",
        "outputId": "308b3f9e-ee9c-440a-da7b-e3cca84e78c3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0041, -0.0079, -0.0217,  ..., -0.0280, -0.0261,  0.0037],\n",
              "        [-0.0113,  0.0126,  0.0127,  ...,  0.0353,  0.0065, -0.0081],\n",
              "        [ 0.0138, -0.0278, -0.0258,  ..., -0.0180,  0.0004, -0.0316],\n",
              "        ...,\n",
              "        [ 0.0088, -0.0297, -0.0208,  ...,  0.0142, -0.0093,  0.0152],\n",
              "        [-0.0082, -0.0283, -0.0317,  ..., -0.0256,  0.0293,  0.0323],\n",
              "        [-0.0344,  0.0069, -0.0272,  ...,  0.0065,  0.0132, -0.0203]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_PooIIWIkJf",
        "outputId": "8a7f3dd1-87f8-443e-f74c-ef9eac642685"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 0.0211,  0.0339, -0.0111, -0.0112, -0.0032,  0.0021,  0.0355, -0.0251,\n",
              "         0.0331,  0.0102], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "  print(images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ob3176caIm4U",
        "outputId": "707dafd1-3f80-44d9-9f7d-218938799973"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([80, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    print(images.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH7Mll-VKYgs",
        "outputId": "ccbefaf6-562b-49c0-8e9e-f899133a2412"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.reshape(128,784).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MbGGOQ5K4DI",
        "outputId": "21a36677-65ac-44dd-c23b-fe19a6d1a23b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "  def forward(self,xb):\n",
        "    xb = xb.reshape(-1,784)\n",
        "    out = self.linear(xb)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "qNcZQQ4AK_Uq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MnistModel()\n",
        "outputs = model(images)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "id": "Pn3kyqS9MZ9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcddd58a-5a85-49f6-f9dc-f6287e5f0a36"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "sy4eSECVMd05"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = F.softmax(model(images), dim=1)"
      ],
      "metadata": {
        "id": "ltL3dsxLgAEw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('sample probabilities:\\n', probs[:2].data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K09jPp7pgKb0",
        "outputId": "15c03edb-00f4-412c-e251-e1789889d6a2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample probabilities:\n",
            " tensor([[0.0972, 0.0667, 0.1058, 0.1252, 0.0836, 0.1381, 0.1368, 0.0663, 0.1049,\n",
            "         0.0754],\n",
            "        [0.0878, 0.0788, 0.1200, 0.1260, 0.1031, 0.1241, 0.0896, 0.0879, 0.0861,\n",
            "         0.0966]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sum: \", torch.sum(probs[0]).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz7D66s_g-RN",
        "outputId": "9519ef0c-9577-4759-9dd4-a3396d1b9bf3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_probs, preds = torch.max(probs, dim=1)\n",
        "print(preds)\n",
        "print(max_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FQ-_-bZhfhY",
        "outputId": "821bdf74-aafc-4837-ab31-3402dd6af145"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5, 3, 8, 3, 3, 3, 2, 2, 4, 6, 2, 3, 2, 3, 5, 2, 5, 6, 5, 3, 6, 6, 3, 9,\n",
            "        8, 5, 6, 5, 3, 8, 4, 7, 3, 3, 3, 2, 2, 3, 6, 5, 6, 5, 2, 6, 7, 6, 5, 6,\n",
            "        8, 3, 5, 6, 2, 6, 8, 3, 3, 2, 3, 6, 3, 6, 3, 2, 3, 8, 3, 3, 3, 3, 2, 6,\n",
            "        7, 6, 2, 3, 3, 6, 2, 3, 4, 3, 3, 6, 5, 3, 3, 3, 6, 7, 2, 3, 2, 2, 6, 6,\n",
            "        6, 2, 3, 3, 3, 2, 6, 2, 6, 9, 5, 5, 6, 8, 3, 3, 3, 5, 8, 6, 9, 5, 2, 6,\n",
            "        2, 3, 2, 2, 6, 6, 4, 3])\n",
            "tensor([0.1381, 0.1260, 0.1305, 0.1478, 0.1460, 0.1332, 0.1510, 0.1178, 0.1179,\n",
            "        0.1319, 0.1565, 0.1165, 0.1310, 0.1248, 0.1172, 0.1240, 0.1468, 0.1216,\n",
            "        0.1484, 0.1408, 0.1180, 0.1506, 0.1381, 0.1144, 0.1208, 0.1379, 0.1180,\n",
            "        0.1175, 0.1296, 0.1251, 0.1264, 0.1231, 0.1456, 0.1430, 0.1182, 0.1240,\n",
            "        0.1287, 0.1316, 0.1434, 0.1538, 0.1252, 0.1457, 0.1324, 0.1460, 0.1303,\n",
            "        0.1278, 0.1393, 0.1143, 0.1431, 0.1270, 0.1354, 0.1262, 0.1364, 0.1276,\n",
            "        0.1478, 0.1414, 0.1190, 0.1445, 0.1576, 0.1260, 0.1429, 0.1307, 0.1248,\n",
            "        0.1305, 0.1186, 0.1285, 0.1354, 0.1292, 0.1428, 0.1248, 0.1195, 0.1445,\n",
            "        0.1321, 0.1341, 0.1466, 0.1332, 0.1446, 0.1271, 0.1316, 0.1275, 0.1236,\n",
            "        0.1185, 0.1404, 0.1869, 0.1418, 0.1297, 0.1289, 0.1355, 0.1404, 0.1293,\n",
            "        0.1313, 0.1404, 0.1419, 0.1218, 0.1429, 0.1372, 0.1270, 0.1214, 0.1335,\n",
            "        0.1295, 0.1477, 0.1557, 0.1248, 0.1305, 0.1137, 0.1100, 0.1282, 0.1345,\n",
            "        0.1473, 0.1142, 0.1322, 0.1385, 0.1593, 0.1476, 0.1374, 0.1360, 0.1149,\n",
            "        0.1222, 0.1316, 0.1273, 0.1376, 0.1243, 0.1518, 0.1580, 0.1232, 0.1475,\n",
            "        0.1227, 0.1193], grad_fn=<MaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item()/len(preds))"
      ],
      "metadata": {
        "id": "PlZ-uHH1h88z"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(outputs, labels)"
      ],
      "metadata": {
        "id": "Tl2ksWVTj2Xl",
        "outputId": "72ea43f3-156d-488a-b23f-fa89d4bfd33a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1250)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SIuoPAcoj19z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = F.cross_entropy"
      ],
      "metadata": {
        "id": "6jJB4AJMkNAF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(outputs, labels)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xuo-r6UIlgnm",
        "outputId": "61ae083b-d9dc-4cf1-ddcd-8a6e5dbbd049"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3571, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "  optimizer = opt_func(model.parameters(),lr)\n",
        "  history = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    for batch in train_loader:\n",
        "      loss = model.training_step(batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    result = evaluate(model, val_loader)\n",
        "    model.epoch_end(epoch, result)\n",
        "    history.append(result)\n",
        "\n",
        "  return history"
      ],
      "metadata": {
        "id": "VreJz3oplssu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "  outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "YmxPBRU4pnOR"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "  def forward(self,xb):\n",
        "    xb = xb.reshape(-1,784)\n",
        "    out = self.linear(xb)\n",
        "    return out\n",
        "\n",
        "  def training_step(self, batch):\n",
        "    images, labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out, labels)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch):\n",
        "    images, labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out, labels)\n",
        "    acc = accuracy(out, labels)\n",
        "    return {'val_loss': loss, 'val_acc': acc}\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "    batch_losses = [x['val_loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()\n",
        "    batch_accs = [x['val_acc'] for x in outputs]\n",
        "    epoch_acc = torch.stack(batch_accs).mean()\n",
        "    return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "  def epoch_end(self, epoch, result):\n",
        "    print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val']['val_loss'], result['val']['val_acc']))\n",
        "\n",
        "model = MnistModel()"
      ],
      "metadata": {
        "id": "zeKBighmqZ2f"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eF-6VpRuqxxA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}